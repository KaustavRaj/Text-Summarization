{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluation Metric.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOMV/JTeF6Nxluv1uId+7gF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaustavRaj/Text-Summarization/blob/master/Evaluation_Metric.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXkn44wBxp6C",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation metric\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JARxjkPHW9Y",
        "colab_type": "code",
        "outputId": "0bdf6ee1-6529-426a-9f41-db93cfeab62f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bmpkc3e0HiD7",
        "colab_type": "code",
        "outputId": "6283094c-bff7-406d-e089-f49fa74c1848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!pip install contractions\n",
        "!pip install rouge"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.6/dist-packages (0.0.24)\n",
            "Requirement already satisfied: textsearch in /usr/local/lib/python3.6/dist-packages (from contractions) (0.0.17)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.4.0)\n",
            "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.1.1)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.6/dist-packages (0.3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSRFLpn4HiJw",
        "colab_type": "code",
        "outputId": "6979e925-0e7f-4dbd-e808-2fad4554fcf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import re\n",
        "import os\n",
        "import pickle\n",
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import contractions\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.CRITICAL)\n",
        "\n",
        "\n",
        "class Summarizer:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.dir_path = '/content/gdrive/My Drive/Colab Notebooks/Summarization/summarization v2'\n",
        "    self._MAX_TEXT_LEN    =  60\n",
        "    self._MAX_SUMMARY_LEN =  10\n",
        "    self._TEXT_PADDING    =  'post'\n",
        "    self.encoder_model = load_model(self.dir_path + '/models/encoder_model.h5')\n",
        "    self.decoder_model = load_model(self.dir_path + '/models/decoder_model.h5')\n",
        "    with open(self.dir_path + '/data/word_indices_mapping.pickle', 'rb') as f:\n",
        "      self.index_to_word_text, self.index_to_word_summary, self.word_to_index_summary = pickle.load(f)\n",
        "    with open(self.dir_path + '/data/tok_x.pickle', 'rb') as f:\n",
        "      self.tok_x = pickle.load(f)\n",
        "\n",
        "\n",
        "  def summarize(self, sent):\n",
        "    \"\"\"wrapper function to test the model\"\"\"\n",
        "\n",
        "    sent = self.cleaner(sent, remove_stopwords=True)\n",
        "    if len(sent.split()) > self._MAX_TEXT_LEN:\n",
        "      return \"make your sentence length less than {} words\".format(self._MAX_TEXT_LEN)\n",
        "\n",
        "    seq = self.tok_x.texts_to_sequences(sent.split())\n",
        "    seq = [[item for sublist in seq for item in sublist]]\n",
        "    seq = pad_sequences(seq, maxlen=self._MAX_TEXT_LEN, padding=self._TEXT_PADDING)\n",
        "    return self.seq2seq_model(seq.reshape(1, self._MAX_TEXT_LEN))\n",
        "\n",
        "\n",
        "  def cleaner(self, text, remove_stopwords=True):\n",
        "    \"\"\"removes url's, nltk's stopwords and anything which is not an alphabet\"\"\"\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text.lower(), flags=re.MULTILINE)\n",
        "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
        "    text = contractions.fix(text, slang=False)\n",
        "    if remove_stopwords:\n",
        "      text = ' '.join([word for word in text.split() if word not in stop_words]).strip()\n",
        "      \n",
        "    return text\n",
        "  \n",
        "\n",
        "  def seq2seq_model(self, input_seq):\n",
        "    \"\"\"summarizes the input text given and returns the summarized string\"\"\"\n",
        "\n",
        "    encoder_out, encoder_h, encoder_c = self.encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = self.word_to_index_summary['stok']\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    while not stop_condition:\n",
        "      output_tokens, h, c = self.decoder_model.predict([target_seq] + [encoder_out, encoder_h, encoder_c])\n",
        "      sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "      sampled_token = self.index_to_word_summary[sampled_token_index]\n",
        "      \n",
        "      if sampled_token != 'etok':\n",
        "        decoded_sentence += sampled_token + ' '\n",
        "        \n",
        "      if sampled_token == 'etok' or len(decoded_sentence.split()) >= (self._MAX_SUMMARY_LEN-1):\n",
        "        stop_condition = True\n",
        "\n",
        "      target_seq = np.zeros((1,1))\n",
        "      target_seq[0, 0] = sampled_token_index\n",
        "      encoder_h, encoder_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlNiQQ1gHiIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir_path = '/content/gdrive/My Drive/Colab Notebooks/Summarization/summarization v2'\n",
        "df = pd.read_csv(dir_path + '/data/prepared_amazon_reviews_dataset.csv')[['text', 'summary']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6UYyM0NHiB9",
        "colab_type": "code",
        "outputId": "ecca632a-ad70-4dbd-8963-e3ef4eb1a5b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bought several vitality canned dog food produc...</td>\n",
              "      <td>stok good quality dog food etok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
              "      <td>stok not as advertised etok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>confection around centuries light pillowy citr...</td>\n",
              "      <td>stok  delight  says it all etok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>looking secret ingredient robitussin believe f...</td>\n",
              "      <td>stok cough medicine etok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great taffy great price wide assortment yummy ...</td>\n",
              "      <td>stok great taffy etok</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text                          summary\n",
              "0  bought several vitality canned dog food produc...  stok good quality dog food etok\n",
              "1  product arrived labeled jumbo salted peanuts p...      stok not as advertised etok\n",
              "2  confection around centuries light pillowy citr...  stok  delight  says it all etok\n",
              "3  looking secret ingredient robitussin believe f...         stok cough medicine etok\n",
              "4  great taffy great price wide assortment yummy ...            stok great taffy etok"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4Z9jQoVuhTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.dropna(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWYBbhFhyReI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66cc6cbb-e052-4172-924e-bcdbfcfb95cd"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70707, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbwaKYztHh8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading our model\n",
        "model = Summarizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PTylxjcu889",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from rouge import Rouge\n",
        "\n",
        "scorer = Rouge()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPel3_iswZID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# storing all the rouge scores\n",
        "rouge_1 = {'f':[], 'p':[], 'r':[]}\n",
        "rouge_2 = {'f':[], 'p':[], 'r':[]}\n",
        "rouge_l = {'f':[], 'p':[], 'r':[]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMMutxIpuZWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(df.shape[0]):\n",
        "  text = df['text'][i]\n",
        "  reference = ' '.join(df['summary'][i].split()[1:-1])\n",
        "  if len(reference) == 0:\n",
        "    continue\n",
        "  hypothesis = model.summarize(text)\n",
        "  scores = scorer.get_scores(hypothesis, reference)[0]\n",
        "  one, two, l = scores['rouge-1'], scores['rouge-2'], scores['rouge-l']\n",
        "  for p, q in one.items():\n",
        "    rouge_1[p].append(q)\n",
        "  for p, q in two.items():\n",
        "    rouge_2[p].append(q)\n",
        "  for p, q in l.items():\n",
        "    rouge_l[p].append(q)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0wft4QExjR1",
        "colab_type": "text"
      },
      "source": [
        "Our average rouge scores are:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVv4P0hMlD7z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b54765c-d868-4251-a975-3cc3f88d6711"
      },
      "source": [
        "np.mean(rouge_1['f']), np.mean(rouge_1['p']), np.mean(rouge_1['r'])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.2784578212176004, 0.3258323772425466, 0.2658607938551489)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or8eArSdwjAB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6dd16136-7980-4b35-d82f-9f283bfbeb4d"
      },
      "source": [
        "np.mean(rouge_2['f']), np.mean(rouge_2['p']), np.mean(rouge_2['r'])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.12287177605435542, 0.14134767031609272, 0.11870969176261821)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7lYJKumwi83",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be0d59ea-0999-44f9-e767-17ffcc835590"
      },
      "source": [
        "np.mean(rouge_l['f']), np.mean(rouge_l['p']), np.mean(rouge_l['r'])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.25834125883560194, 0.3227466068601844, 0.26382645947286665)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}